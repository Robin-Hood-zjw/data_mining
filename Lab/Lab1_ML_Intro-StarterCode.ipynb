{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn is an open source Python machine learning module. Using scikit-learn makes it easy to implement a variety of machine learning tasks including regression, classification, clustering, dimensionality reduction, model selection and data pre-processing. The full documentation for scikit-learn is located at https://scikit-learn.org/stable/. It contains numerous examples and detailed descriptions for each function (and its associated parameters). This notebook will give you a brief introduction on how to implement the basic machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are missing any of the packages, uncomment the line(s) below to install\n",
    "# %pip install sklearn\n",
    "# %pip install pandas\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & Previewing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn library contains a few small datasets that we can experiment with. Descriptions of the datasets are included here: https://scikit-learn.org/stable/datasets/toy_dataset.html. We will use two of them in this tutorial:\n",
    "\n",
    "1) The Boston house prices dataset (for regression tasks) and\n",
    "\n",
    "2) The breast cancer wisconsin (diagnostic) dataset (for classification tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the datasets using helper functions and will take a look at the contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)\n",
    "(boston_X, boston_y) = load_boston(return_X_y=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)\n",
    "(cancer_X, cancer_y) = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before interacting with our datasets any further, we must split the data into training and testing data. This way we can use the training data to explore the data and fit our models and then use the testing data to provide an unbiased measure of the performance of our models. This can be done using the train_test_split function in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data with a 75%-25% training-test split\n",
    "# set the random state for reproducible results\n",
    "\n",
    "boston_X_train, boston_X_test, boston_y_train, boston_y_test = train_test_split(\n",
    "                                boston_X, boston_y, test_size=0.25, random_state=671)\n",
    "#checks\n",
    "print(boston_X_train.shape)\n",
    "print(boston_X_test.shape)\n",
    "print(boston_y_train.shape)\n",
    "print(boston_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE: split the breast cancer data with a train-test split of 70%-30% & random_state of 671 into:\n",
    "# (1) cancer_X_train\n",
    "# (2) cancer_X_test\n",
    "# (3) cancer_y_train\n",
    "# (4) cancer_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost all datasets, we will need to preprocess the data before we can fit any models. This may involve imputing missing data, scaling our features, applying one-hot encoding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Imputing Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a very common problem across all datasets. One simple strategy for addressing it is to impute missing values using a chosen strategy such as the \"mean\", \"median\" or \"most_frequent\". First, let's check for missing data in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_X_train_df = pd.DataFrame(boston_X_train, columns=boston.feature_names)\n",
    "# check for which columns have missing values\n",
    "columns = boston_X_train_df.columns[boston_X_train_df.isnull().any()]\n",
    "print(len(columns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_X_train_df = pd.DataFrame(cancer_X_train, columns=cancer.feature_names)\n",
    "# check for which columns have missing values\n",
    "columns = cancer_X_train_df.columns[cancer_X_train_df.isnull().any()]\n",
    "print(len(columns)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these are \"toy\" datasets, they do not have any missing values but let us still practice how we would impute missing values anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # impute using the 'mean' for the feature\n",
    "boston_X_train_imp = imp.fit_transform(boston_X_train) # use fit_transform on training data\n",
    "boston_X_test_imp = imp.transform(boston_X_test) # use transform on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE: apply the SimpleImputer with a 'median' strategy to the cancer data\n",
    "### As a result, you should have two variables: \n",
    "#(1) cancer_X_train_imp and\n",
    "#(2) cancer_X_test_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the nature of our data and the ML models we want to implement, we may need to one-hot encode the categorical variables in our data as some models do not support categorical inputs. This means we will transform the feature into a set of dummy variables.\n",
    "\n",
    "Although we do not have any categorical variables in our cancer dataset, we do have a variable, 'RAD', in our boston dataset that we want to one-hot encode as it represents an index of accessibility to radial highways. We can do so using a OneHotEncoder and ColumnTransfer, which allows us to only apply the OneHotEncoder to only the 'RAD' column.\n",
    "\n",
    "First, let's implement the OneHotEncoder with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "rad_idx = list(boston.feature_names).index('RAD') # find the index of the 'RAD' column\n",
    "enc_boston = ColumnTransformer([(\"RAD\", OneHotEncoder(),[rad_idx])], remainder=\"passthrough\") # passthrough specifies to keep other columns as they are\n",
    "boston_X_train_enc = enc_boston.fit_transform(boston_X_train_imp) # use fit_transform on training data\n",
    "boston_X_test_enc = enc_boston.transform(boston_X_test_imp) # use transform on testing data\n",
    "print(enc_boston.transformers_)\n",
    "\n",
    "print(boston_X_train_enc.shape)\n",
    "print(boston_X_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after applying the OneHotEncoder to the 'RAD' column, we have increased the number of columns in our dataset from 13 to 21 as it added one column for each unique value of 'RAD'. However, if we use this, we will run into the issue of multicollinearity since each dummy variable can be represented as a linear combination of the other dummy variables. To solve this issue, we want to create n-1 dummy variables. This can be done using the 'drop' parameter of the OneHotEncoder function, as shown below, resulting in one less column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_boston = ColumnTransformer([(\"RAD\", OneHotEncoder(drop='first'),[rad_idx])], remainder=\"passthrough\")\n",
    "boston_X_train_enc = enc_boston.fit_transform(boston_X_train_imp)\n",
    "boston_X_test_enc = enc_boston.transform(boston_X_test_imp)\n",
    "print(enc_boston.transformers_)\n",
    "\n",
    "print(boston_X_train_enc.shape)\n",
    "print(boston_X_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some machine learning models, we must first scale the features so that they are all on a shared scale. This supports faster model convergence and removes any bias toward features with higher magnitudes (i.e., giving more importance to features on a scale of cm vs. inches).\n",
    "\n",
    "\n",
    "Two of the most common techniques for feature normalization are 1) StandardScaler and 2) MinMaxScaler. StandardScaler works by adjusting the mean of each feature to zero with a standard deviation of 1. MinMaxScaler works by scaling all values to between 0 and 1. There are no hard rules for when to use one over the other but some factors to consider are the problem we intend to solve, assumptions regarding the distribution of the data (including the presence of outliers) and the ML models we plan on implementing. It can also be a good option to try out both and see which results in better performance. Either way, we must fit the scaler on our training data and then transform our testing data using it to avoid any data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "boston_X_train_scal = scaler.fit_transform(boston_X_train_enc) # use fit_transform on training data\n",
    "boston_X_test_scal = scaler.transform(boston_X_test_enc) # use transform on testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "### YOUR CODE: apply MinMaxScaler to the cancer dataset ('cancer_X_train_imp' and 'cancer_X_test_imp')\n",
    "### name the resulting variables 'cancer_X_train_scal' and 'cancer_X_test_scal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have large datasets with high dimensionality, feature selection can help us reduce the dimensionality (e.g., the number of input variables or features) by removing irrelevant or redundant features. This can help with reducing the computational costs associated with training models and can also improve the performance of our models in some cases. There are many feature selection techniques so we will only experiment with a few here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Mutual Information (regression)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k = 10) # select the top 10 features\n",
    "boston_X_train_mi = selector.fit_transform(boston_X_train_scal, boston_y_train)\n",
    "print(\"Training data shape (after applying Mutual Info):\", boston_X_train_mi.shape)\n",
    "boston_X_test_mi = selector.transform(boston_X_test_scal)\n",
    "print(\"Testing data shape (after applying Mutual Info):\", boston_X_test_mi.shape)\n",
    "\n",
    "# Method 2: Principal component analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 0.90) # can specify either the percent of explained variance or number of features\n",
    "boston_X_train_pca = pca.fit_transform(boston_X_train_scal, boston_y_train)\n",
    "print(\"Training shape (after applying PCA):\", boston_X_train_pca.shape)\n",
    "boston_X_test_pca = pca.transform(boston_X_test_scal)\n",
    "print(\"Testing shape (after applying PCA):\", boston_X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: apply Mutual Information (classification) to the breast cancer data\n",
    "# select the top 15 features and name the resulting variables 'cancer_X_train_mi' & 'cancer_X_test_mi'\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting, Cross-Validation & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally fit some models! scikit-learn allows you to easily implement a variety of models. We will work with a few of them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by fitting two models - (1) Linear Regression and (2) K-Nearest Neighbors Regression - to our boston housing dataset. We will fit the models to each of the three feature sets - (1) all of the features (no feature selection), (2) the feature subset selected using mutual information and (3) the feature subset selected using PCA so that we can compare performance both between the models and the different feature subsets. We will use cross-validation (3 folds in this example) to get a more reliable estimate of the performance of our models without having to touch our test dataset yet. The default performance metric will be $R^2$, or the proportion of explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr_scores_df = pd.DataFrame(columns=[\"R^2 on Fold 1\", \"R^2 on Fold 2\", \"R^2 on Fold 3\", \"Mean R^2\"])\n",
    "print(\"Linear Regression:\")\n",
    "lr_scal_scores = list(cross_val_score(lr, boston_X_train_scal, boston_y_train, cv=3))\n",
    "lr_scal_scores.append(np.mean(lr_scal_scores))\n",
    "lr_scores_df.loc[\"No Feature Selection\"] = lr_scal_scores\n",
    "lr_mi_scores = list(cross_val_score(lr, boston_X_train_mi, boston_y_train, cv=3))\n",
    "lr_mi_scores.append(np.mean(lr_mi_scores))\n",
    "lr_scores_df.loc[\"MI Features\"] = lr_mi_scores\n",
    "lr_pca_scores = list(cross_val_score(lr, boston_X_train_pca, boston_y_train, cv=3))\n",
    "lr_pca_scores.append(np.mean(lr_pca_scores))\n",
    "lr_scores_df.loc[\"PCA Features\"] = lr_pca_scores\n",
    "print(lr_scores_df.head())\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "knn_scores_df = pd.DataFrame(columns=[\"R^2 on Fold 1\", \"R^2 on Fold 2\", \"R^2 on Fold 3\", \"Mean R^2\"])\n",
    "print(\"\\nK-Nearest Neighbors Regression:\")\n",
    "knn_scal_scores = list(cross_val_score(knn, boston_X_train_scal, boston_y_train, cv=3))\n",
    "knn_scal_scores.append(np.mean(knn_scal_scores))\n",
    "knn_scores_df.loc[\"No Feature Selection\"] = knn_scal_scores\n",
    "knn_mi_scores = list(cross_val_score(knn, boston_X_train_mi, boston_y_train, cv=3))\n",
    "knn_mi_scores.append(np.mean(knn_mi_scores))\n",
    "knn_scores_df.loc[\"MI Features\"] = knn_mi_scores\n",
    "knn_pca_scores = list(cross_val_score(knn, boston_X_train_pca, boston_y_train, cv=3))\n",
    "knn_pca_scores.append(np.mean(knn_pca_scores))\n",
    "knn_scores_df.loc[\"PCA Features\"] = knn_pca_scores\n",
    "print(knn_scores_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we see that linear regression performs similarily across the feature subsets but for KNN, we see that the model performs significantly better on the feature subset chosen using mutual information. Let's use GridSearchCV below to see if we can further improve its performance by adjusting the value of n_neighbors (the number of neighbors used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# search over n_neighbors\n",
    "param_grid = [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7] }]\n",
    "\n",
    "cv_knn = GridSearchCV(knn, param_grid, cv=2)\n",
    "cv_knn.fit(boston_X_train_mi, boston_y_train)\n",
    "print(\"Best Params:\", cv_knn.best_params_)\n",
    "print(\"Best R^2 Score:\", cv_knn.best_score_)\n",
    "print(cv_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV, we see that the the value of n_neighbors resulting in the best performance was 3. Let's use this as our final model and apply it to our test set. We will evaluate the test set using Mean Squared Error (MSE) and Mean Absolute Error (MAE), two common measures of model performance for regression tasks. The formula for MSE is:\n",
    "\n",
    "$\\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i )^2$ \n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the actual observation and $\\hat{y}_i$ is our prediction\n",
    "\n",
    "Similarly, the formula for MAE:\n",
    "\n",
    "$\\frac{1}{n}\\sum_{i=1}^n|(y_i - \\hat{y}_i )|$ \n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the actual observation and $\\hat{y}_i$ is our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "knn.fit(boston_X_train_mi, boston_y_train)\n",
    "preds = knn.predict(boston_X_test_mi)\n",
    "\n",
    "print(\"Training R^2:\", knn.score(boston_X_train_mi, boston_y_train))\n",
    "print(\"Testing R^2:\", knn.score(boston_X_test_mi, boston_y_test))\n",
    "print(\"MSE:\", mean_squared_error(boston_y_test, preds)) \n",
    "print(\"MAE:\", mean_absolute_error(boston_y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our testing score increased to 0.84! Now, let's move onto the breast cancer data, a classification task..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores_df = pd.DataFrame(columns=[\"Fold 1 Accuracy\", \"Fold 2 Accuracy\", \"Fold 3 Accuracy\", \"Mean Accuracy\"])\n",
    "print(\"Random Forest Classifier:\")\n",
    "rf_scal_scores = list(cross_val_score(rf, cancer_X_train_scal, cancer_y_train, cv=3))\n",
    "rf_scal_scores.append(np.mean(rf_scal_scores))\n",
    "rf_scores_df.loc[\"All Features\"] = rf_scal_scores\n",
    "rf_mi_scores = list(cross_val_score(rf, cancer_X_train_mi, cancer_y_train, cv=3))\n",
    "rf_mi_scores.append(np.mean(rf_mi_scores))\n",
    "rf_scores_df.loc[\"MI Features\"] = rf_mi_scores\n",
    "print(rf_scores_df.head())\n",
    "\n",
    "\n",
    "### YOUR CODE: find another classifier of your choice from scikit-learn & replicate the code above using it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example to show that feature selection will not always improve performance. This is why we must experiment with different methods and models to optimize them for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lot of classification tasks, we will want to focus our evaluation on precision, recall and the f1-score. The classification_report function in scikit-learn makes it easy to do so. As a review:\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$, or the fraction of our positive predictions that are actually positive instances\n",
    "\n",
    "Recall = $\\frac{TP}{TP + FN}$, or the fraction of positive instances that we actually predict as positive\n",
    "\n",
    "F1-score = $2*\\: \\frac{precision\\: *\\: recall}{precision + recall}$, or the harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "### YOUR CODE: using your chosen model, compute predictions for the test data\n",
    "### use these predictions to create the classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
